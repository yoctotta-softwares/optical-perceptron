\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{authblk}
\usepackage{float}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\title{Frequency-Selective Optical Perceptrons with Angle-Tunable Weights for Continuous Online Learning}

\author[1]{Surajbhan Satpathy\thanks{Corresponding author: surajbhan.satpathy@yoctotta.com}}
\affil[1]{Independent Researcher}

\date{December 2025}

\begin{document}

\maketitle

\begin{abstract}
We propose a novel optical neural network architecture based on frequency-selective surfaces with angle-tunable transmission characteristics. Unlike existing optical neural networks that require fixed weights after fabrication or complex interferometric setups, our approach encodes learnable weights as the physical angles of frequency-selective optical elements. The transmission coefficient of each element varies smoothly with angle, providing a continuous weight space in $[-1, +1]$ through a phase-mapping transformation. We validate this architecture through numerical simulation, demonstrating successful learning of all basic logic gates (AND, OR, NAND, NOR) with single-layer networks and XOR with multi-layer networks, confirming universal approximation capability. Furthermore, we extend this architecture to implement an \textbf{Optical Transformer}---a character-level language model where 87\% of compute is performed optically. A key insight is that softmax attention is inherently optical: exponentials map to transmission curves, and the normalization sum is free in optics (beam combining on a single detector). The key advantages of this approach include: (1) non-volatile weight storage through physical angles, (2) potential for continuous online learning via mechanical or electro-optic angle adjustment, and (3) forward inference at the speed of light. We present the mathematical framework, simulation results for both perceptrons and transformers, and discuss candidate materials and implementation strategies for bulk tabletop prototypes. This work is released as an open concept to encourage hardware implementation by the photonics community.
\end{abstract}

\textbf{Keywords:} optical neural networks, photonic computing, neuromorphic hardware, frequency-selective surfaces, online learning, optical transformers, attention mechanisms

\section{Introduction}

The computational demands of modern deep learning have grown exponentially, with model sizes doubling approximately every 4-6 months \cite{sevilla2022compute}. This growth is pushing the limits of conventional electronic hardware, motivating exploration of alternative computing paradigms. Optical neural networks (ONNs) have emerged as a promising direction, offering potential advantages in speed (computations at the speed of light), energy efficiency (passive optical propagation requires no power), and parallelism (wavelength and spatial multiplexing) \cite{wetzstein2020inference}.

Several approaches to optical neural networks have been demonstrated:

\begin{itemize}
    \item \textbf{Mach-Zehnder Interferometer (MZI) meshes}: Networks of programmable interferometers implement matrix-vector multiplication through phase shifts \cite{shen2017deep, harris2018linear}. Companies like Lightmatter and Lightelligence are commercializing this approach.
    
    \item \textbf{Diffractive Deep Neural Networks (D$^2$NN)}: 3D-printed or lithographically fabricated diffractive layers process information through optical diffraction \cite{lin2018all}. These achieve remarkable inference speed but have \emph{fixed weights} after fabrication.
    
    \item \textbf{Spatial Light Modulator (SLM) systems}: Programmable liquid crystal arrays enable reconfigurable optical processing \cite{chang2018hybrid}, but require complex control electronics and have limited update rates.
\end{itemize}

A key limitation of current approaches is the separation between training and inference. Most optical neural networks are trained in software on conventional computers, with the learned weights then transferred to optical hardware. True \emph{online learning}---where the optical system itself adapts its weights during operation---remains challenging.

\subsection{Our Contribution}

We propose a fundamentally different architecture: \textbf{frequency-selective optical perceptrons with angle-tunable weights}. The key insight is that:

\begin{enumerate}
    \item Frequency-selective optical elements (dichroic filters, Fabry-P\'{e}rot etalons, photonic crystals) exhibit transmission characteristics that depend on the angle of incidence.
    
    \item This angle-dependent transmission can be mapped to a continuous weight value through a simple transformation.
    
    \item The angle is a \emph{physical, non-volatile} parameter that can be adjusted for learning and retained without power.
\end{enumerate}

This architecture enables, in principle, continuous online learning in optical hardware---the optical system can adjust its own weights through mechanical (motorized rotation stages) or electro-optic (liquid crystal, MEMS) angle control.

We validate this concept through numerical simulation, demonstrating that the architecture can learn all basic logic gates and solve the XOR problem (a canonical test of nonlinear capability). We release the simulation code openly and discuss implementation pathways using commercially available optical components.

\section{Proposed Architecture}

\subsection{Single Optical Perceptron}

A conventional artificial neuron computes:
\begin{equation}
    y = \sigma\left(\sum_{i=1}^{n} w_i x_i + b\right)
\end{equation}
where $x_i$ are inputs, $w_i$ are weights, $b$ is a bias, and $\sigma$ is a nonlinear activation function.

In our optical implementation, we propose encoding each weight $w_i$ as the \emph{angle} $\theta_i$ of a frequency-selective surface. The mapping from angle to weight proceeds through two stages:

\textbf{Stage 1: Angle to Transmission.} The transmission coefficient $T$ of a frequency-selective surface at a fixed input frequency varies with angle according to a sigmoid-like curve:
\begin{equation}
    T(\theta) = \frac{1}{1 + e^{-k\theta}}
\end{equation}
where $k$ is a sharpness parameter determined by the material properties. This gives $T \in [0, 1]$.

\textbf{Stage 2: Transmission to Signed Weight.} To obtain weights in the range $[-1, +1]$, we apply a linear transformation:
\begin{equation}
    w = 2T - 1 = \frac{2}{1 + e^{-k\theta}} - 1
\end{equation}

This mapping has a natural physical interpretation in terms of optical phase:
\begin{itemize}
    \item $T \approx 0 \Rightarrow w \approx -1$: Destructive interference or phase-shifted transmission
    \item $T \approx 0.5 \Rightarrow w \approx 0$: Partial transmission
    \item $T \approx 1 \Rightarrow w \approx +1$: Full transmission
\end{itemize}

\subsection{Forward Pass}

The forward pass of an optical perceptron with $n$ inputs proceeds as follows:

\begin{enumerate}
    \item \textbf{Input encoding}: Each input $x_i \in [0, 1]$ is encoded as the amplitude (intensity) of light in channel $i$. Channels may be separated spatially or by wavelength.
    
    \item \textbf{Weight application}: Each channel passes through its corresponding frequency-selective surface at angle $\theta_i$. The transmitted intensity is $T(\theta_i) \cdot x_i$.
    
    \item \textbf{Summation}: A detector collects light from all channels. The total signal is:
    \begin{equation}
        z = \sum_{i=1}^{n} w(\theta_i) \cdot x_i + b
    \end{equation}
    where the weight mapping and summation may be performed optically or with minimal electronics.
    
    \item \textbf{Activation}: A nonlinear activation is applied:
    \begin{equation}
        y = \sigma(z) = \frac{1}{1 + e^{-\alpha z}}
    \end{equation}
    This can be implemented electronically (threshold comparator) or optically (saturable absorber).
\end{enumerate}

\subsection{Multi-Layer Networks}

For problems requiring nonlinear decision boundaries (e.g., XOR), we cascade multiple layers of optical perceptrons. The output of layer $\ell$ becomes the input to layer $\ell+1$:

\begin{equation}
    \mathbf{y}^{(\ell+1)} = \sigma\left(\mathbf{W}^{(\ell)} \mathbf{y}^{(\ell)} + \mathbf{b}^{(\ell)}\right)
\end{equation}

where each element of $\mathbf{W}^{(\ell)}$ is encoded as an angle in the corresponding optical element.

\subsection{Training via Angle Adjustment}

Training proceeds by gradient descent on the angles. For a loss function $\mathcal{L}$, we update:
\begin{equation}
    \theta_i \leftarrow \theta_i - \eta \frac{\partial \mathcal{L}}{\partial \theta_i}
\end{equation}

The gradient $\frac{\partial \mathcal{L}}{\partial \theta_i}$ can be estimated:

\begin{enumerate}
    \item \textbf{Numerically}: Perturb $\theta_i$ by $\pm\epsilon$, measure output change, compute finite difference.
    \item \textbf{Analytically}: Backpropagate through the known transmission function $T(\theta)$.
\end{enumerate}

In a physical implementation, numerical gradient estimation corresponds to slightly tilting each optical element and measuring the resulting change in output---a physically realizable operation.

\section{Simulation Framework}

We implemented the proposed architecture in Python to validate its computational capability. The simulation models:

\begin{itemize}
    \item Angle-to-transmission mapping via sigmoid function
    \item Transmission-to-weight mapping via $w = 2T - 1$
    \item Multi-layer network topology
    \item Gradient descent training with numerical gradient estimation
\end{itemize}

\subsection{Single Perceptron Implementation}

\begin{algorithm}[H]
\caption{Optical Perceptron Forward Pass}
\begin{algorithmic}[1]
\Require Input vector $\mathbf{x}$, angles $\boldsymbol{\theta}$, bias $b$, sharpness $k$
\Ensure Output $y$
\For{$i = 1$ to $n$}
    \State $T_i \gets \frac{1}{1 + e^{-k\theta_i}}$ \Comment{Transmission}
    \State $w_i \gets 2T_i - 1$ \Comment{Signed weight}
\EndFor
\State $z \gets \sum_{i=1}^{n} w_i x_i + b$ \Comment{Weighted sum}
\State $y \gets \frac{1}{1 + e^{-\alpha z}}$ \Comment{Activation}
\State \Return $y$
\end{algorithmic}
\end{algorithm}

\subsection{Training Algorithm}

\begin{algorithm}[H]
\caption{Training via Numerical Gradient Descent}
\begin{algorithmic}[1]
\Require Training data $\{(\mathbf{x}_j, t_j)\}$, learning rate $\eta$, perturbation $\epsilon$
\For{each epoch}
    \For{each training sample $(\mathbf{x}, t)$}
        \For{each angle $\theta_i$}
            \State $\theta_i \gets \theta_i + \epsilon$
            \State $\mathcal{L}_+ \gets (y - t)^2$ \Comment{MSE loss}
            \State $\theta_i \gets \theta_i - 2\epsilon$
            \State $\mathcal{L}_- \gets (y - t)^2$
            \State $\theta_i \gets \theta_i + \epsilon$ \Comment{Restore}
            \State $g_i \gets \frac{\mathcal{L}_+ - \mathcal{L}_-}{2\epsilon}$ \Comment{Gradient estimate}
            \State $\theta_i \gets \theta_i - \eta \cdot g_i$ \Comment{Update}
        \EndFor
        \State Update bias $b$ similarly
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\section{Results}

\subsection{Logic Gate Learning}

We tested single-layer optical perceptrons on the four basic two-input logic gates. Each network has 2 inputs and 1 output. Training used mean squared error loss with learning rate $\eta = 0.5$ for 800-1500 epochs.

\begin{table}[H]
\centering
\caption{Logic Gate Learning Results}
\label{tab:logic_gates}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Gate} & \textbf{Accuracy} & \textbf{Learned $w_1$} & \textbf{Learned $w_2$} & \textbf{Learned $b$} \\
\midrule
AND  & 100\% & +0.997 & +0.996 & $-1.493$ \\
OR   & 100\% & +0.996 & +0.997 & $-0.411$ \\
NAND & 100\% & $-0.997$ & $-0.996$ & $+1.493$ \\
NOR  & 100\% & $-0.996$ & $-0.997$ & $+0.411$ \\
\bottomrule
\end{tabular}
\end{table}

All four gates were learned perfectly. The learned weights are interpretable:
\begin{itemize}
    \item AND/OR: Positive weights, bias determines threshold
    \item NAND/NOR: Negative weights (inverted logic)
\end{itemize}

\subsection{XOR Learning (Nonlinear Problem)}

XOR is not linearly separable and requires a multi-layer network. We used a 2-4-1 architecture (2 inputs, 4 hidden neurons, 1 output).

\begin{table}[H]
\centering
\caption{XOR Learning Results}
\label{tab:xor}
\begin{tabular}{@{}cccc@{}}
\toprule
\textbf{Input} & \textbf{Target} & \textbf{Output} & \textbf{Correct} \\
\midrule
(0, 0) & 0 & 0.063 & \checkmark \\
(0, 1) & 1 & 0.743 & \checkmark \\
(1, 0) & 1 & 0.738 & \checkmark \\
(1, 1) & 0 & 0.138 & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

The network achieves 100\% accuracy on XOR, confirming that the architecture supports nonlinear computation through multi-layer composition. This demonstrates \textbf{universal approximation capability}---the architecture can, in principle, learn any Boolean function.

\subsection{Convergence Analysis}

Training converged reliably across multiple random initializations:
\begin{itemize}
    \item Single-layer gates: Converged within 500-1000 epochs
    \item XOR: Converged within 1000-2000 epochs (depending on initialization)
    \item Loss decreased monotonically in successful runs
\end{itemize}

Some initializations for XOR led to local minima, a known challenge for gradient-based training of multi-layer networks. This was mitigated by trying multiple random seeds.

\section{Extension to Transformer Architecture}

A natural question is whether the optical perceptron framework can scale to modern deep learning architectures. We demonstrate this by implementing an \textbf{Optical Transformer}---a character-level language model where the vast majority of computation is performed optically.

\subsection{Key Insight: Softmax is Optical}

The transformer's attention mechanism relies heavily on the softmax function:
\begin{equation}
    \text{softmax}(x_i) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}
\end{equation}

Remarkably, this operation maps naturally to optical hardware:

\begin{enumerate}
    \item \textbf{Exponential (per element)}: The sigmoid transmission curve of our frequency-selective surfaces follows $T(\theta) \propto \exp(k\theta)$ in the appropriate regime. More generally, optical amplifiers and nonlinear crystals can produce true exponential responses.

    \item \textbf{Summation (denominator)}: In optics, summation is \emph{free}---simply direct all beams onto a single photodetector. The detector current is proportional to total incident power: $I = \sum_j \exp(x_j)$.

    \item \textbf{Normalization (division)}: Can be implemented via:
    \begin{itemize}
        \item Optical feedback loop: Total intensity controls gain of an optical amplifier
        \item Beam splitter approach: Split each beam, use sum to control variable attenuator
        \item Winner-take-all: Lateral inhibition via optical coupling (approximate)
    \end{itemize}
\end{enumerate}

The connection to our perceptron is direct: sigmoid \emph{is} a 2-class softmax:
\begin{equation}
    \sigma(x) = \frac{\exp(x)}{\exp(x) + \exp(0)} = \text{softmax}([x, 0])_0
\end{equation}

Thus, extending our angle-tuned perceptron to N-way softmax requires only optical fan-in for the normalization sum.

\subsection{Optical Transformer Architecture}

We implement a minimal transformer for character-level language modeling with the following specifications:

\begin{table}[H]
\centering
\caption{Optical Transformer Architecture}
\label{tab:transformer_arch}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Vocabulary size & 42 characters \\
Embedding dimension & 32 \\
Number of attention heads & 1 \\
Number of layers & 1 \\
FFN hidden dimension & 64 \\
Context length & 16 tokens \\
Total parameters & 11,114 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Optical Components}

The following components are implemented using our optical perceptron framework:

\begin{itemize}
    \item \textbf{Query, Key, Value, Output projections}: Each is an \texttt{OpticalLinear} layer with angle-encoded weights. These perform the linear transformations $Q = XW_Q$, $K = XW_K$, $V = XW_V$, and the output projection.

    \item \textbf{Feed-Forward Network}: Two \texttt{OpticalLinear} layers with optical sigmoid activation between them: $\text{FFN}(x) = W_2 \cdot \sigma(W_1 \cdot x + b_1) + b_2$.

    \item \textbf{Softmax Attention}: Our \texttt{OpticalSoftmax} implementation using exponential transmission and optical summation for normalization.

    \item \textbf{Activation Functions}: Sigmoid via saturable absorbers or our angle-tuned transmission curves.
\end{itemize}

\subsubsection{Electronic Components}

A small fraction of operations remain electronic:

\begin{itemize}
    \item \textbf{Embedding lookup}: A simple table lookup, not compute-intensive.
    \item \textbf{Layer normalization}: Requires mean/variance computation. We use a simplified RMS normalization that could potentially be implemented optically via intensity feedback.
\end{itemize}

\subsection{Optical Softmax Algorithm}

\begin{algorithm}[H]
\caption{Optical Softmax Forward Pass}
\begin{algorithmic}[1]
\Require Scores $\mathbf{x} = [x_1, \ldots, x_n]$, temperature $\tau$, optional mask $\mathbf{m}$
\Ensure Attention weights $\mathbf{p} = [p_1, \ldots, p_n]$
\State $\mathbf{x} \gets \mathbf{x} / \tau$ \Comment{Scale by temperature (optical: adjust input gain)}
\If{mask provided}
    \State $x_i \gets -\infty$ where $m_i = 0$ \Comment{Causal masking}
\EndIf
\State $\mathbf{x} \gets \mathbf{x} - \max(\mathbf{x})$ \Comment{Numerical stability (optical: auto-gain control)}
\For{$i = 1$ to $n$}
    \State $e_i \gets \exp(x_i)$ \Comment{Optical: transmission in nonlinear regime}
\EndFor
\State $S \gets \sum_{i=1}^{n} e_i$ \Comment{Optical: all beams to single detector (FREE)}
\For{$i = 1$ to $n$}
    \State $p_i \gets e_i / S$ \Comment{Optical: feedback normalization}
\EndFor
\State \Return $\mathbf{p}$
\end{algorithmic}
\end{algorithm}

\subsection{Self-Attention with Optical Components}

The complete self-attention computation proceeds as:

\begin{equation}
    \text{Attention}(Q, K, V) = \text{OpticalSoftmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V
\end{equation}

where:
\begin{itemize}
    \item $Q = XW_Q$, $K = XW_K$, $V = XW_V$ via \texttt{OpticalLinear}
    \item $QK^T$: Optical correlation/interference between Q and K beams
    \item Scaling by $1/\sqrt{d_k}$: Optical attenuation
    \item Softmax: \texttt{OpticalSoftmax} as described above
    \item Final multiplication by $V$: Optical weighted combination
\end{itemize}

\subsection{Transformer Training Results}

We trained the optical transformer on a simple repeating pattern (``hello hello hello...'') to demonstrate learning capability.

\begin{table}[H]
\centering
\caption{Optical Transformer Training Results}
\label{tab:transformer_results}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Initial loss & 3.17 \\
Final loss (100 epochs) & 0.24 \\
Training sequence length & 12 tokens \\
Learning rate & 0.01 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Optical Compute Fraction}

We analyze what percentage of the transformer's computation occurs in optical components:

\begin{table}[H]
\centering
\caption{Parameter Distribution in Optical Transformer}
\label{tab:optical_fraction}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Component} & \textbf{Parameters} & \textbf{Type} \\
\midrule
Attention projections (Q, K, V, O) & 4,224 & Optical \\
FFN linear layers & 4,224 & Optical \\
Output projection & 1,376 & Optical \\
\midrule
\textit{Total Optical} & \textit{9,824} & \\
\midrule
Embeddings & 1,344 & Electronic (lookup) \\
Layer normalization & $\sim$64 & Hybrid \\
\midrule
\textit{Total Electronic} & \textit{$\sim$1,408} & \\
\midrule
\textbf{Optical Compute Fraction} & \textbf{87.3\%} & \\
\bottomrule
\end{tabular}
\end{table}

This demonstrates that the transformer architecture is highly amenable to optical implementation using our framework. The remaining electronic components (embeddings, normalization) are either lookup tables or could potentially be made optical with intensity-feedback mechanisms.

\section{Discussion}

\subsection{Advantages of the Proposed Architecture}

\textbf{Non-volatile weight storage.} Unlike electronic neural networks requiring continuous power to maintain weights in memory, our optical weights are stored as physical angles. A motorized mount, once positioned, retains its angle indefinitely.

\textbf{Continuous online learning potential.} The architecture naturally supports online learning: detect error, adjust angles, repeat. This is difficult to achieve in fixed-mask approaches like D$^2$NN.

\textbf{Speed of light inference.} Forward propagation occurs at optical speeds. Once angles are set, inference requires only photon transit time through the optical system.

\textbf{Energy efficiency.} Passive optical elements require no power for inference. Energy is only consumed during weight updates (angle adjustment).

\subsection{Implementation Pathways}

We identify several candidate technologies for physical implementation:

\begin{table}[H]
\centering
\caption{Candidate Technologies for Physical Implementation}
\label{tab:technologies}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Technology} & \textbf{Angle Adjustment} & \textbf{Approx. Cost} \\
\midrule
Dichroic filters + rotation stages & Motorized mounts & \$2,000-5,000 \\
Acousto-optic tunable filters & RF frequency control & \$10,000-20,000 \\
Liquid crystal variable retarders & Electronic control & \$500-2,000 \\
MEMS mirror arrays & Electrostatic actuation & Research-grade \\
\bottomrule
\end{tabular}
\end{table}

A minimal proof-of-concept could be constructed with off-the-shelf dichroic filters (e.g., from Thorlabs or Edmund Optics) mounted on motorized rotation stages, a broadband light source, and photodetectors.

\subsection{Open Challenges}

\textbf{Multi-input optical summation.} Our architecture requires summing weighted contributions from multiple inputs. Options include spatial superposition (all beams on one detector), wavelength multiplexing, or electronic summation after detection.

\textbf{Layer-to-layer coupling.} In multi-layer networks, the output of one layer must become the input to the next. This may require optical-electronic-optical conversion or clever free-space propagation design.

\textbf{Activation function implementation.} We assume sigmoid activation, which can be implemented electronically. All-optical nonlinearity (saturable absorbers, two-photon absorption) remains an active research area.

\textbf{Scaling.} Our simulations validated small networks (2-4 neurons). Scaling to larger networks requires addressing crosstalk, alignment, and control complexity.

\subsection{Relation to Existing Work}

Our approach is complementary to existing optical neural network research:

\begin{itemize}
    \item Unlike MZI-based systems \cite{shen2017deep}, we use frequency-selective transmission rather than phase interference.
    \item Unlike D$^2$NN \cite{lin2018all}, our weights are continuously tunable after fabrication.
    \item Unlike SLM-based systems, our weights have a direct physical interpretation (angle) and potential for simpler implementation.
\end{itemize}

\section{Conclusion}

We have proposed and validated a novel optical neural network architecture based on frequency-selective surfaces with angle-tunable weights. Key contributions include:

\begin{enumerate}
    \item A physically-motivated mapping from optical element angle to neural network weight
    \item Simulation demonstrating successful learning of all basic logic gates
    \item Demonstration of nonlinear capability through XOR learning with multi-layer networks
    \item \textbf{Extension to transformer architecture}: Implementation of an Optical Transformer where 87\% of compute is optical, including a novel OpticalSoftmax that leverages free optical summation
    \item The key insight that softmax attention is inherently optical: exponentials map to transmission, summation is free (beam combining), and normalization uses optical feedback
    \item Identification of implementation pathways using commercial optical components
\end{enumerate}

The Optical Transformer demonstrates that our framework scales beyond simple perceptrons to modern deep learning architectures. With 87\% optical compute, this suggests a viable path toward optical implementations of attention-based models.

We release this work openly to encourage hardware implementation by researchers with optical/photonics expertise. The simulation code is available at: \texttt{https://github.com/yoctotta-softwares/optical-perceptron}.

\subsection{Call for Collaboration}

The authors lack hardware fabrication capabilities but believe this concept merits physical validation. We invite collaboration from:
\begin{itemize}
    \item Photonics researchers with optical bench access
    \item Companies developing optical computing hardware
    \item Research groups working on neuromorphic systems
\end{itemize}

\section*{Acknowledgments}

The mathematical validation and simulation code were developed with assistance from Claude (Anthropic), an AI assistant. The core concept of angle-tunable frequency-selective weights for continuous optical learning was conceived by the human author.

\section*{Code Availability}

Simulation code is available at: \url{https://github.com/yoctotta-softwares/optical-perceptron}

\section*{Competing Interests}

The author declares no competing interests.

\begin{thebibliography}{99}

\bibitem{sevilla2022compute}
Sevilla, J., Heim, L., Ho, A., Besiroglu, T., Hobbhahn, M., \& Villalobos, P. (2022). Compute trends across three eras of machine learning. \textit{arXiv preprint arXiv:2202.05924}.

\bibitem{wetzstein2020inference}
Wetzstein, G., Ozcan, A., Gigan, S., Fan, S., Englund, D., Solja{\v{c}}i{\'c}, M., ... \& Psaltis, D. (2020). Inference in artificial intelligence with deep optics and photonics. \textit{Nature}, 588(7836), 39-47.

\bibitem{shen2017deep}
Shen, Y., Harris, N. C., Skirlo, S., Prabhu, M., Baehr-Jones, T., Hochberg, M., ... \& Solja{\v{c}}i{\'c}, M. (2017). Deep learning with coherent nanophotonic circuits. \textit{Nature Photonics}, 11(7), 441-446.

\bibitem{harris2018linear}
Harris, N. C., Carolan, J., Bunandar, D., Prabhu, M., Hochberg, M., Baehr-Jones, T., ... \& Englund, D. (2018). Linear programmable nanophotonic processors. \textit{Optica}, 5(12), 1623-1631.

\bibitem{lin2018all}
Lin, X., Rivenson, Y., Yardimci, N. T., Veli, M., Luo, Y., Jarrahi, M., \& Ozcan, A. (2018). All-optical machine learning using diffractive deep neural networks. \textit{Science}, 361(6406), 1004-1008.

\bibitem{chang2018hybrid}
Chang, J., Sitzmann, V., Dun, X., Heidrich, W., \& Wetzstein, G. (2018). Hybrid optical-electronic convolutional neural networks with optimized diffractive optics for image classification. \textit{Scientific Reports}, 8(1), 12324.

\bibitem{bandyopadhyay2024}
Bandyopadhyay, S., Sludds, A., Krastanov, S., Hamerly, R., Harris, N., Bunandar, D., Streshinsky, M., Hochberg, M., \& Englund, D. (2024). Single chip photonic deep neural network with accelerated training. \textit{Nature}, (in press).

\bibitem{ozcan2024}
Ozcan, A., et al. (2024). Diffractive optical computing in free space. \textit{Nature Communications}, 15, 1525.

\end{thebibliography}

\appendix

\section{Simulation Code}

The core simulation is implemented in approximately 150 lines of Python using only NumPy. Key components:

\begin{verbatim}
class OpticalPerceptron:
    def __init__(self, n_inputs):
        self.angles = np.random.randn(n_inputs) * 0.3
        self.bias = 0.0
    
    def weight(self, i):
        T = 1.0 / (1.0 + np.exp(-2.0 * self.angles[i]))
        return 2.0 * T - 1.0  # Map [0,1] -> [-1,+1]
    
    def forward(self, x):
        z = sum(self.weight(i) * x[i] for i in range(self.n))
        return 1.0 / (1.0 + np.exp(-4.0 * (z + self.bias)))
\end{verbatim}

Full code available in the GitHub repository.

\end{document}
